# The Role of AI

What is the role of AI chatbots (CAI) in psychotherapy?

There is unfortunately not much research surrounding efficacy as of now. 

## AI as digital therapist
Defining AI as a digital therapist will incur much higher standards of performance, ethics, and the same standards to human therapists.


## A2 AI as digital therapist


AI should not be an agent in the same way a human is because it does not have intentionality (See [[Searle]], [[Mind Models]]). This means that CAI cannot explain its reasoning in the same way as people (See [[AI Interpretability]]), and that AI cannot hold normative stances.

The first person perspective is important to therapy, and a quantitative machine (AI) cannot utilize it. Further more, objectivization of emotions could detach people form their experience. Because CAI can only simulate having a therapeutic conversation (while not *really* having it), CAI must be situated such that it protects patients autonomy and beneficence.  (Sedlakova & Trachsel 2022)

When AI is described as a type of therapist, it takes on all of the expectations of care, sympathy, and relationality of a human therapist. By purporting that these machines which have none of these qualities indeed do have these qualities, bioethical principles are broken as it is medical deception (See [[Bioethical Principles]]). 

## AI as tool for therapists
Defining AI as a tool, the only normative question lies in conditions of safety, reliability, or risk mitigation

By merely using AI as a tool, it ignores the wider potential impact for doing good with AI. (Sedlakova & Trachsel 2022)

## Something In Between
"If CAI were merely a tool, it would ignore the wider implications because it engages users in conversation, can lead to building a relationship and can be perceived as an agent. If CAI were an agent, it would ignore that CAI is mimicking the conversation, does not have human features like empathy or intentionality and cannot be a bearer of responsibility as humans are." (Sedlakova & Trachsel 2022)

"On the one hand, CAI does not have enough properties of being an appropriate partner in conversation...On the other hand, CAI has epistemic supremacy in the conversation because it can provide data and analysis of a scale that humans would not be able to. " (Sedlakova & Trachsel 2022)